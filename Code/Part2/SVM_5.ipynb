{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd1ef17b-68c7-4be9-a775-11eee0c5d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83568700-e437-4acf-bee9-ee2fe75e53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined feature and label arrays\n",
    "X = np.concatenate([np.load('X_comcuc.npy'), np.load('X_cowpig1.npy'),\n",
    "                     np.load('X_eucdov.npy'), np.load('X_eueowl1.npy'),\n",
    "                     np.load('X_grswoo.npy'), np.load('X_tawowl1.npy')])\n",
    "\n",
    "y = np.concatenate([np.load('comcuc_combined_labels.npy'), np.load('cowpig1_combined_labels.npy'),\n",
    "                     np.load('eucdov_combined_labels.npy'), np.load('eueowl1_combined_labels.npy'),\n",
    "                     np.load('grswoo_combined_labels.npy'), np.load('tawowl1_combined_labels.npy')])\n",
    "\n",
    "# Combine the feature and label arrays into a single dataset\n",
    "dataset = np.hstack((X, y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca1a1d59-7e1d-4a25-a4a0-f4cac3dfd45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique labels in the dataset\n",
    "num_labels = len(np.unique(y))\n",
    "\n",
    "# Initialize an empty list to store the stratified samples\n",
    "stratified_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f45b516e-b8f4-4d4f-a197-6879a7bd7ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each label\n",
    "for label in range(num_labels):\n",
    "    # Get the indices of instances with the current label\n",
    "    indices = np.where(y == label)[0]\n",
    "    \n",
    "    # Get the number of instances with the current label\n",
    "    num_instances = len(indices)\n",
    "    \n",
    "    # Split the instances into training and validation sets using stratified sampling\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.5, stratify=y[indices])\n",
    "    \n",
    "    # Add the training instances to the stratified sample list\n",
    "    stratified_samples.append(train_indices)\n",
    "    \n",
    "# Concatenate the stratified samples into a single list of indices\n",
    "stratified_indices = np.concatenate(stratified_samples)\n",
    "\n",
    "# Use the stratified indices to select a subset of instances from the dataset\n",
    "subset_dataset = dataset[stratified_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49efde26-f137-4a7b-ade8-b58711180a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 255)\n"
     ]
    }
   ],
   "source": [
    "print(subset_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39e3888b-bed3-49c0-a15a-e4b88b8a648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X = subset_dataset[:, :-1]  # Features\n",
    "y = subset_dataset[:, -1]   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e1ec29-d24c-4410-b434-f59b1bda9e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = SVC()\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9424ef1c-e2cc-4507-b7ca-f08d5dd2d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.9102485443231381\n",
      "Average F1 score: 0.8169193068243954\n",
      "Average training accuracy: 0.9520283689937985\n",
      "Average training F1 score: 0.9069535775539965\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db67475a-b2c5-4008-8265-c5f017422379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = SVC(C=0.1)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "190beeee-c825-4843-a4e1-afdf583e2690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8594143261938495\n",
      "Average F1 score: 0.6569836250455194\n",
      "Average training accuracy: 0.8685436461349889\n",
      "Average training F1 score: 0.6828261941251613\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b9983c-ba7c-48ca-96e9-2fc750cedb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = SVC(C=5)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603aa78d-7342-42ce-9321-2e5eb6e2b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.919198667944551\n",
      "Average F1 score: 0.8436770480927127\n",
      "Average training accuracy: 0.987770629336028\n",
      "Average training F1 score: 0.9777224255887262\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d4289f-e364-4ca5-8fc1-7c7be2dba6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = SVC(kernel='poly')\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6662a7-718c-4c2c-a641-1f51b6cf4363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8853481248437369\n",
      "Average F1 score: 0.7555651529804173\n",
      "Average training accuracy: 0.9306530117814955\n",
      "Average training F1 score: 0.8590170320232481\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9836e1bc-6a64-43a8-a884-21b5a2158606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
