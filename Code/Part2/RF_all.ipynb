{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144b00ab-be14-4c55-8c24-03066e385ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2909fd11-8030-4152-afdd-f157ee35e6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined feature and label arrays\n",
    "X = np.concatenate([np.load('X_comcuc.npy'), np.load('X_cowpig1.npy'),\n",
    "                     np.load('X_eucdov.npy'), np.load('X_eueowl1.npy'),\n",
    "                     np.load('X_grswoo.npy'), np.load('X_tawowl1.npy')])\n",
    "\n",
    "y = np.concatenate([np.load('comcuc_combined_labels.npy'), np.load('cowpig1_combined_labels.npy'),\n",
    "                     np.load('eucdov_combined_labels.npy'), np.load('eueowl1_combined_labels.npy'),\n",
    "                     np.load('grswoo_combined_labels.npy'), np.load('tawowl1_combined_labels.npy')])\n",
    "\n",
    "# Combine the feature and label arrays into a single dataset\n",
    "dataset = np.hstack((X, y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8df981d-e8fb-4a8e-b2fd-5fcfd402403e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique labels in the dataset\n",
    "num_labels = len(np.unique(y))\n",
    "\n",
    "# Initialize an empty list to store the stratified samples\n",
    "stratified_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a65bcbd4-9042-4f1f-8403-3604abc78e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each label\n",
    "for label in range(num_labels):\n",
    "    # Get the indices of instances with the current label\n",
    "    indices = np.where(y == label)[0]\n",
    "    \n",
    "    # Get the number of instances with the current label\n",
    "    num_instances = len(indices)\n",
    "    \n",
    "    # Split the instances into training and validation sets using stratified sampling\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.5, stratify=y[indices])\n",
    "    \n",
    "    # Add the training instances to the stratified sample list\n",
    "    stratified_samples.append(train_indices)\n",
    "    \n",
    "# Concatenate the stratified samples into a single list of indices\n",
    "stratified_indices = np.concatenate(stratified_samples)\n",
    "\n",
    "# Use the stratified indices to select a subset of instances from the dataset\n",
    "subset_dataset = dataset[stratified_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d70b4c46-a019-42b8-8213-b1baa153de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 255)\n"
     ]
    }
   ],
   "source": [
    "print(subset_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf887264-b563-4d03-9235-5db42f11d287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X = subset_dataset[:, :-1]  # Features\n",
    "y = subset_dataset[:, -1]   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3ef80f1-48e0-4acc-9af2-29f07d3a3cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a47a419-45c6-41ea-8639-2ca1bdcf87e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.849430905353224\n",
      "Average F1 score: 0.6512648422715933\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f763a54-7269-4baa-a743-f690f3dd7ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8498642845237103\n",
      "Average F1 score: 0.6507215979718446\n",
      "Average training accuracy: 0.9999166653645564\n",
      "Average training F1 score: 0.9998938545119331\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9610a5b-e3ba-4f32-a54c-8541590c3ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 10\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbb958ed-0fc5-4b10-a9b1-28b8c97ed1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8518476246041006\n",
      "Average F1 score: 0.6562012460890234\n",
      "Average training accuracy: 0.999914813408753\n",
      "Average training F1 score: 0.9998930069970788\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d077dfa-6ec6-4a95-a40b-bb873dae690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_depth=5)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c9a16ea-aa70-4a24-88c9-ba57384c9ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7206620746173293\n",
      "Average F1 score: 0.168417748023534\n",
      "Average training accuracy: 0.7228578852337202\n",
      "Average training F1 score: 0.17938183795553145\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1fd46c8-fe39-4585-8de9-0cc6e2265ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_depth=20)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c8f68a1b-9c25-4366-a7b2-898500e81e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.844597505347668\n",
      "Average F1 score: 0.6377781061822454\n",
      "Average training accuracy: 0.9678911319333041\n",
      "Average training F1 score: 0.9408241651481708\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c59cf245-4410-4ddc-b40a-55626e8546e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_depth=50)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8af1bfe1-2772-4d64-bc9d-d112fd86a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8485809192432703\n",
      "Average F1 score: 0.6497511557476886\n",
      "Average training accuracy: 0.9977791294263074\n",
      "Average training F1 score: 0.9961438634760311\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcd3036c-b903-4290-bf69-e2af94e1da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_depth=35)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "418af572-f639-4f0f-824c-28dcde045047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8487809234102842\n",
      "Average F1 score: 0.6488135696172306\n",
      "Average training accuracy: 0.9907706789898401\n",
      "Average training F1 score: 0.9835923894012069\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4665e44-c94e-445b-aa04-aeb6b2e97848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_features=5)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ffb4b49-121e-4c51-8333-8ec578df3fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7960466288857405\n",
      "Average F1 score: 0.49479969780623934\n",
      "Average training accuracy: 0.9999291654513636\n",
      "Average training F1 score: 0.9999206118021174\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fdec19c-8d24-4892-bcb6-f4ff7c64a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier\n",
    "clf = RandomForestClassifier(max_features=10)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "869b52e7-a7c4-491f-b082-42a17e944512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8350807108925743\n",
      "Average F1 score: 0.6127577677303335\n",
      "Average training accuracy: 0.999920832031223\n",
      "Average training F1 score: 0.9999114460683203\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8832ce7b-5895-42a5-92ad-e8eeac1f6f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the classifier with the parameters you want to adjust\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=5, min_samples_leaf=2, max_features=50)\n",
    "\n",
    "# define the number of folds\n",
    "n_folds = 10\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1af54cc5-82e7-4061-851d-299840399e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.8696145579818859\n",
      "Average F1 score: 0.7003238103122598\n",
      "Average training accuracy: 0.967030932534416\n",
      "Average training F1 score: 0.9391370917123293\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97256f68-b0c2-428d-8e94-f687560d69fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
