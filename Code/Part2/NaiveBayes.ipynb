{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c329c85f-27d1-45cc-97dc-6ffda60786f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a4c3ef99-94f4-4532-8f22-0a7bd9e389c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the combined feature and label arrays\n",
    "X = np.concatenate([np.load('X_comcuc.npy'), np.load('X_cowpig1.npy'),\n",
    "                     np.load('X_eucdov.npy'), np.load('X_eueowl1.npy'),\n",
    "                     np.load('X_grswoo.npy'), np.load('X_tawowl1.npy')])\n",
    "\n",
    "y = np.concatenate([np.load('comcuc_combined_labels.npy'), np.load('cowpig1_combined_labels.npy'),\n",
    "                     np.load('eucdov_combined_labels.npy'), np.load('eueowl1_combined_labels.npy'),\n",
    "                     np.load('grswoo_combined_labels.npy'), np.load('tawowl1_combined_labels.npy')])\n",
    "\n",
    "# Combine the feature and label arrays into a single dataset\n",
    "dataset = np.hstack((X, y.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fba2b9bf-2ca5-48e4-be35-2fca233be8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of unique labels in the dataset\n",
    "num_labels = len(np.unique(y))\n",
    "\n",
    "# Initialize an empty list to store the stratified samples\n",
    "stratified_samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d6cc095-67d9-49fb-ab3d-f449eedd67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over each label\n",
    "for label in range(num_labels):\n",
    "    # Get the indices of instances with the current label\n",
    "    indices = np.where(y == label)[0]\n",
    "    \n",
    "    # Get the number of instances with the current label\n",
    "    num_instances = len(indices)\n",
    "    \n",
    "    # Split the instances into training and validation sets using stratified sampling\n",
    "    train_indices, val_indices = train_test_split(indices, test_size=0.5, stratify=y[indices])\n",
    "    \n",
    "    # Add the training instances to the stratified sample list\n",
    "    stratified_samples.append(train_indices)\n",
    "    \n",
    "# Concatenate the stratified samples into a single list of indices\n",
    "stratified_indices = np.concatenate(stratified_samples)\n",
    "\n",
    "# Use the stratified indices to select a subset of instances from the dataset\n",
    "subset_dataset = dataset[stratified_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0edac7f-8d35-409e-84ff-7625e211ba8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59999, 255)\n"
     ]
    }
   ],
   "source": [
    "print(subset_dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51f58569-37ee-46eb-8492-390c3496a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X = subset_dataset[:, :-1]  # Features\n",
    "y = subset_dataset[:, -1]   # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7eded0f5-4094-4207-a8b4-8232b70b29b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cb47b749-b311-442d-8a3f-aee00bd3ce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7107951426507764\n",
      "Average F1 score: 0.4722152114629634\n",
      "Average training accuracy: 0.7120952052820544\n",
      "Average training F1 score: 0.4764449697062701\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c39272d8-5494-4b4c-994f-e7bacdd26231",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "# define the number of folds\n",
    "n_folds = 10\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "acba88a4-dd4b-4341-af06-ee67a8555197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7105618436406067\n",
      "Average F1 score: 0.47227877261289486\n",
      "Average training accuracy: 0.7119340889714693\n",
      "Average training F1 score: 0.4761454208268555\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8192ed38-0aa7-421e-9ae8-37506bd097e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(var_smoothing=0.1)\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dd49fca7-6bcd-419e-8dbb-e428f4236e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7446457899269383\n",
      "Average F1 score: 0.33090576838112157\n",
      "Average training accuracy: 0.7449624193559587\n",
      "Average training F1 score: 0.33229911821546304\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8b4b9a8c-4d3c-4c29-b1e9-da89834fe4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(var_smoothing=10)\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2538a799-f390-43f4-a95a-06886c1a6726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7113285954385088\n",
      "Average F1 score: 0.11876147609480052\n",
      "Average training accuracy: 0.7113285267227789\n",
      "Average training F1 score: 0.1187619023109769\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "08fab607-dcfe-44e2-93df-8813da751bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(var_smoothing=1e-12)\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2709d57c-315f-4463-81af-d1e1f021f9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7107951426507764\n",
      "Average F1 score: 0.4722152114629634\n",
      "Average training accuracy: 0.7120952052820544\n",
      "Average training F1 score: 0.4764449697062701\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e589890a-364d-4170-8f4c-de2839232a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB(var_smoothing=1e-20)\n",
    "# define the number of folds\n",
    "n_folds = 5\n",
    "\n",
    "# initialize lists to store the results\n",
    "acc_scores = []\n",
    "f1_scores = []\n",
    "train_acc_scores = []\n",
    "train_f1_scores = []\n",
    "\n",
    "# initialize the KFold object\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45fdf4b6-8ab1-4dfb-885e-53ef71078e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Average accuracy: 0.7107951426507764\n",
      "Average F1 score: 0.4722152114629634\n",
      "Average training accuracy: 0.7120952052820544\n",
      "Average training F1 score: 0.4764449697062701\n"
     ]
    }
   ],
   "source": [
    "# loop over the folds\n",
    "for train_idx, test_idx in kf.split(X):\n",
    "\n",
    "    # split the data into training and testing sets\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "\n",
    "    # fit the classifier to the training data\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # predict the labels of the testing data\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions\n",
    "    acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "\n",
    "    # predict the labels of the training data\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "\n",
    "    # compute the accuracy and F1 score of the predictions on the training data\n",
    "    train_acc_scores.append(accuracy_score(y_train, y_train_pred))\n",
    "    train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "    print(1)\n",
    "# print the average accuracy and F1 score across the folds\n",
    "print(\"Average accuracy:\", sum(acc_scores)/n_folds)\n",
    "print(\"Average F1 score:\", sum(f1_scores)/n_folds)\n",
    "\n",
    "# print the average training accuracy and F1 score across the folds\n",
    "print(\"Average training accuracy:\", sum(train_acc_scores)/n_folds)\n",
    "print(\"Average training F1 score:\", sum(train_f1_scores)/n_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d48f5e0-c481-4442-9cc4-83ef9c331030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
